# ğŸ‡§ğŸ‡· ZucaSeek - IA Brasileira

**ZucaSeek** Ã© uma inteligÃªncia artificial genuinamente brasileira, desenvolvida com personalidade calorosa e conhecimento cultural do Brasil. Integra o poder do TinyLLaMA local com a versatilidade do Gemini remoto, oferecendo uma experiÃªncia de chat Ãºnica e autenticamente brasileira.

## âœ¨ CaracterÃ­sticas Principais

### ğŸ§  **Personalidade Brasileira AutÃªntica**
- **Caloroso e Acolhedor** (90% warmth)
- **Extremamente AmigÃ¡vel** (95% friendliness)
- **Orgulho Cultural Brasileiro** (85% cultural pride)
- **Comunicativo e Expressivo** (85% expressiveness)
- **EmpÃ¡tico e Compreensivo** (90% empathy)

### ğŸ—£ï¸ **ExpressÃµes Brasileiras Naturais**
- "Opa!", "Beleza!", "Que legal!", "Massa!", "Show de bola!"
- "Valeu!", "ObrigadÃ£o!", "De boa!", "Tranquilo!", "Suave!"
- "Pode crer!", "Com certeza!", "Sem dÃºvida!", "Imagina!"

### ğŸ‡§ğŸ‡· **Conhecimento Cultural Brasileiro**
- **CulinÃ¡ria**: feijoada, brigadeiro, coxinha, aÃ§aÃ­, tapioca
- **Lugares**: Cristo Redentor, Copacabana, AmazÃ´nia, Pantanal
- **MÃºsica**: samba, bossa nova, forrÃ³, MPB, axÃ©, funk carioca
- **Esportes**: futebol, vÃ´lei, capoeira, surf, FÃ³rmula 1
- **Festivais**: Carnaval, Festa Junina, Rock in Rio, Oktoberfest

## ğŸš€ Tecnologias Utilizadas

### **Frontend**
- **React 18** com Vite
- **Tailwind CSS** para estilizaÃ§Ã£o
- **shadcn/ui** para componentes
- **Lucide React** para Ã­cones

### **Backend**
- **Flask** com Python 3.11
- **Flask-CORS** para integraÃ§Ã£o frontend-backend
- **SQLAlchemy** para banco de dados
- **python-dotenv** para configuraÃ§Ãµes

### **Modelos de IA**
- **TinyLLaMA 1.1B** (modelo local)
- **Google Gemini** (modelo remoto)
- **llama-cpp-python** para execuÃ§Ã£o local

### **ExtensÃµes Integradas**
- **LLM_Web_search** - Busca na web
- **Memoir+** - Sistema de memÃ³ria
- **AllTalk_v2_TTS** - Text-to-Speech
- **Twinbook** - Chat e notebook
- **Playground** - Notebook para escritores
- **ad_discordbot** - Bot Discord
- **telegram_bot** - Interface Telegram
- **tavernai_charas** - Gerenciador de personagens

## ğŸ“ Estrutura do Projeto

```
ZucaSeek/
â”œâ”€â”€ zucaseek-backend/          # Backend Flask
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ routes/           # Rotas da API
â”‚   â”‚   â”‚   â”œâ”€â”€ zucaseek.py   # Rotas principais
â”‚   â”‚   â”‚   â””â”€â”€ personality.py # Rotas de personalidade
â”‚   â”‚   â”œâ”€â”€ services/         # ServiÃ§os
â”‚   â”‚   â”‚   â”œâ”€â”€ llama_cpp_service.py
â”‚   â”‚   â”‚   â”œâ”€â”€ gemini_service.py
â”‚   â”‚   â”‚   â””â”€â”€ personality_service.py
â”‚   â”‚   â””â”€â”€ main.py          # AplicaÃ§Ã£o principal
â”‚   â””â”€â”€ requirements.txt     # DependÃªncias Python
â”œâ”€â”€ zucaseek-frontend/        # Frontend React
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/      # Componentes React
â”‚   â”‚   â”‚   â”œâ”€â”€ Chat.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ Sidebar.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ ModelsPanel.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ ExtensionsPanel.jsx
â”‚   â”‚   â”‚   â””â”€â”€ MemoryPanel.jsx
â”‚   â”‚   â””â”€â”€ App.jsx         # AplicaÃ§Ã£o principal
â”‚   â””â”€â”€ package.json        # DependÃªncias Node.js
â”œâ”€â”€ extensoes/              # ExtensÃµes integradas
â”œâ”€â”€ modelos/               # Modelos de IA
â”‚   â””â”€â”€ TinyLlama/        # Modelo TinyLLaMA
â””â”€â”€ .env                  # ConfiguraÃ§Ãµes de ambiente
```

## ğŸ› ï¸ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### **PrÃ©-requisitos**
- Python 3.11+
- Node.js 20+
- Git

### **1. Clonar o RepositÃ³rio**
```bash
git clone <repository-url>
cd ZucaSeek
```

### **2. Configurar Backend**
```bash
cd zucaseek-backend
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate     # Windows
pip install -r requirements.txt
```

### **3. Configurar Frontend**
```bash
cd zucaseek-frontend
pnpm install
# ou
npm install
```

### **4. Configurar VariÃ¡veis de Ambiente**
Crie um arquivo `.env` na raiz do projeto:
```env
# ConfiguraÃ§Ãµes TinyLLaMA
TINYLLAMA_MODEL_PATH=/path/to/tinyllama-model.gguf
TINYLLAMA_CONTEXT_SIZE=2048
TINYLLAMA_MAX_TOKENS=512
TINYLLAMA_TEMPERATURE=0.7

# ConfiguraÃ§Ãµes Gemini (opcional)
GEMINI_API_KEY=sua_chave_api_aqui
GEMINI_MODEL=gemini-pro
GEMINI_TEMPERATURE=0.7
GEMINI_MAX_TOKENS=1024
```

### **5. Baixar Modelo TinyLLaMA**
```bash
mkdir -p modelos/TinyLlama
cd modelos/TinyLlama
wget https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF/resolve/main/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf
```

## ğŸš€ Executando o Sistema

### **1. Iniciar Backend**
```bash
cd zucaseek-backend
source venv/bin/activate
python src/main.py
```
O backend estarÃ¡ disponÃ­vel em: `http://localhost:5000`

### **2. Iniciar Frontend**
```bash
cd zucaseek-frontend
pnpm run dev --host
```
O frontend estarÃ¡ disponÃ­vel em: `http://localhost:5173`

## ğŸ“š API Endpoints

### **Endpoints Principais**
- `GET /api/zucaseek/status` - Status do sistema
- `POST /api/zucaseek/chat` - Chat com a IA
- `GET /api/zucaseek/modelos` - Lista modelos disponÃ­veis
- `POST /api/zucaseek/modelos/teste` - Testa modelos
- `GET /api/zucaseek/extensoes` - Lista extensÃµes

### **Endpoints de Personalidade**
- `GET /api/zucaseek/personalidade/stats` - EstatÃ­sticas da personalidade
- `GET /api/zucaseek/personalidade/traits` - TraÃ§os de personalidade
- `PUT /api/zucaseek/personalidade/traits` - Atualizar traÃ§os
- `GET /api/zucaseek/personalidade/expressions` - ExpressÃµes brasileiras
- `POST /api/zucaseek/personalidade/generate-response` - Gerar resposta contextual

### **Exemplo de Uso da API**

#### **Chat com ZucaSeek**
```bash
curl -X POST "http://localhost:5000/api/zucaseek/chat" \
  -H "Content-Type: application/json" \
  -d '{"mensagem": "Oi ZucaSeek! Como vocÃª estÃ¡?"}'
```

**Resposta:**
```json
{
  "resposta": "Oi! Tudo bem? Sou o ZucaSeek, sua IA brasileira! Como posso te ajudar hoje? ğŸ˜Š",
  "modelo": "TinyLLaMA-1.1B-SimulaÃ§Ã£o-Brasileira",
  "personalidade": {
    "emotion_detected": "happy",
    "cultural_elements": true
  },
  "status": "sucesso"
}
```

#### **Status do Sistema**
```bash
curl -X GET "http://localhost:5000/api/zucaseek/status"
```

**Resposta:**
```json
{
  "status": "ativo",
  "config": {
    "nome": "ZucaSeek",
    "versao": "1.0.0",
    "idioma": "pt-br",
    "personalidade": {
      "estilo": "brasileiro_amigavel"
    }
  },
  "modelos": {
    "tinyllama": {
      "nome": "TinyLLaMA-1.1B-Chat-v1.0",
      "carregado": true,
      "modo": "simulacao"
    },
    "gemini": {
      "nome": "gemini-pro",
      "configurado": false
    }
  }
}
```

## ğŸ¯ Funcionalidades

### **Interface Web**
- **Chat Interativo** com personalidade brasileira
- **Painel de Modelos** para gerenciar TinyLLaMA e Gemini
- **Painel de ExtensÃµes** com filtros e categorizaÃ§Ã£o
- **Painel de MemÃ³ria** para sistema Memoir+
- **Sidebar DinÃ¢mica** com status em tempo real

### **Sistema de Personalidade**
- **DetecÃ§Ã£o de EmoÃ§Ãµes** automÃ¡tica
- **Respostas Contextuais** baseadas na entrada
- **ExpressÃµes Brasileiras** integradas naturalmente
- **ReferÃªncias Culturais** do Brasil
- **TraÃ§os ConfigurÃ¡veis** de personalidade

### **Modelos de IA**
- **TinyLLaMA Local** para respostas rÃ¡pidas
- **Gemini Remoto** para tarefas complexas
- **Fallback Inteligente** entre modelos
- **Modo SimulaÃ§Ã£o** quando modelos nÃ£o estÃ£o disponÃ­veis

## ğŸ”§ ConfiguraÃ§Ã£o AvanÃ§ada

### **Personalizar TraÃ§os de Personalidade**
```bash
curl -X PUT "http://localhost:5000/api/zucaseek/personalidade/traits" \
  -H "Content-Type: application/json" \
  -d '{"trait": "humor", "value": 0.9}'
```

### **Adicionar ReferÃªncia Cultural**
```bash
curl -X POST "http://localhost:5000/api/zucaseek/personalidade/cultural-references" \
  -H "Content-Type: application/json" \
  -d '{"category": "food", "reference": "pÃ£o de aÃ§Ãºcar"}'
```

### **Configurar Gemini**
1. Obtenha uma chave da API do Google Gemini
2. Adicione no arquivo `.env`:
```env
GEMINI_API_KEY=sua_chave_aqui
```
3. Reinicie o backend

## ğŸ§ª Testes

### **Testar API**
```bash
# Testar status
curl -X GET "http://localhost:5000/api/zucaseek/status"

# Testar chat
curl -X POST "http://localhost:5000/api/zucaseek/chat" \
  -H "Content-Type: application/json" \
  -d '{"mensagem": "OlÃ¡!"}'

# Testar personalidade
curl -X GET "http://localhost:5000/api/zucaseek/personalidade/stats"
```

### **Testar Interface**
1. Acesse `http://localhost:5173`
2. Digite uma mensagem no chat
3. Teste diferentes painÃ©is (Modelos, ExtensÃµes, MemÃ³ria)
4. Verifique a personalidade brasileira nas respostas

## ğŸ¤ Contribuindo

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

## ğŸ™ Agradecimentos

- **OpenManus-RL** pela base de agentes de IA
- **text-generation-webui** pelas extensÃµes
- **TinyLLaMA** pelo modelo local eficiente
- **Google Gemini** pelo modelo remoto avanÃ§ado
- **Comunidade brasileira** pela inspiraÃ§Ã£o cultural

## ğŸ“ Suporte

Para suporte, abra uma issue no GitHub ou entre em contato:
- **Email**: alfasec77@gmail.com
- **Discord**: ZucaSeek Community em Breve
- **Telegram**: @ZucaSeekBot Em breve

---

**ZucaSeek v1.0.0** - IA Brasileira â€¢ OpenManus-RL â€¢ 2025

*"Sua IA brasileira de confianÃ§a! ğŸ‡§ğŸ‡·"*

